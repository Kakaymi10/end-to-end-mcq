{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting pandas\n",
      "  Using cached pandas-2.2.2-cp312-cp312-win_amd64.whl.metadata (19 kB)\n",
      "Requirement already satisfied: numpy>=1.26.0 in c:\\users\\user\\practices\\end-to-end-mcq\\myenv\\lib\\site-packages (from pandas) (1.26.4)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in c:\\users\\user\\practices\\end-to-end-mcq\\myenv\\lib\\site-packages (from pandas) (2.9.0.post0)\n",
      "Collecting pytz>=2020.1 (from pandas)\n",
      "  Using cached pytz-2024.1-py2.py3-none-any.whl.metadata (22 kB)\n",
      "Collecting tzdata>=2022.7 (from pandas)\n",
      "  Using cached tzdata-2024.1-py2.py3-none-any.whl.metadata (1.4 kB)\n",
      "Requirement already satisfied: six>=1.5 in c:\\users\\user\\practices\\end-to-end-mcq\\myenv\\lib\\site-packages (from python-dateutil>=2.8.2->pandas) (1.16.0)\n",
      "Using cached pandas-2.2.2-cp312-cp312-win_amd64.whl (11.5 MB)\n",
      "Using cached pytz-2024.1-py2.py3-none-any.whl (505 kB)\n",
      "Using cached tzdata-2024.1-py2.py3-none-any.whl (345 kB)\n",
      "Installing collected packages: pytz, tzdata, pandas\n",
      "Successfully installed pandas-2.2.2 pytz-2024.1 tzdata-2024.1\n"
     ]
    }
   ],
   "source": [
    "!pip install pandas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "import pandas as pd\n",
    "import traceback"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting langchain_community\n",
      "  Downloading langchain_community-0.2.16-py3-none-any.whl.metadata (2.7 kB)\n",
      "Requirement already satisfied: PyYAML>=5.3 in c:\\users\\user\\practices\\end-to-end-mcq\\myenv\\lib\\site-packages (from langchain_community) (6.0.2)\n",
      "Requirement already satisfied: SQLAlchemy<3,>=1.4 in c:\\users\\user\\practices\\end-to-end-mcq\\myenv\\lib\\site-packages (from langchain_community) (2.0.34)\n",
      "Requirement already satisfied: aiohttp<4.0.0,>=3.8.3 in c:\\users\\user\\practices\\end-to-end-mcq\\myenv\\lib\\site-packages (from langchain_community) (3.10.5)\n",
      "Collecting dataclasses-json<0.7,>=0.5.7 (from langchain_community)\n",
      "  Downloading dataclasses_json-0.6.7-py3-none-any.whl.metadata (25 kB)\n",
      "Requirement already satisfied: langchain<0.3.0,>=0.2.16 in c:\\users\\user\\practices\\end-to-end-mcq\\myenv\\lib\\site-packages (from langchain_community) (0.2.16)\n",
      "Requirement already satisfied: langchain-core<0.3.0,>=0.2.38 in c:\\users\\user\\practices\\end-to-end-mcq\\myenv\\lib\\site-packages (from langchain_community) (0.2.38)\n",
      "Requirement already satisfied: langsmith<0.2.0,>=0.1.0 in c:\\users\\user\\practices\\end-to-end-mcq\\myenv\\lib\\site-packages (from langchain_community) (0.1.116)\n",
      "Requirement already satisfied: numpy<2.0.0,>=1.26.0 in c:\\users\\user\\practices\\end-to-end-mcq\\myenv\\lib\\site-packages (from langchain_community) (1.26.4)\n",
      "Requirement already satisfied: requests<3,>=2 in c:\\users\\user\\practices\\end-to-end-mcq\\myenv\\lib\\site-packages (from langchain_community) (2.32.3)\n",
      "Requirement already satisfied: tenacity!=8.4.0,<9.0.0,>=8.1.0 in c:\\users\\user\\practices\\end-to-end-mcq\\myenv\\lib\\site-packages (from langchain_community) (8.5.0)\n",
      "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in c:\\users\\user\\practices\\end-to-end-mcq\\myenv\\lib\\site-packages (from aiohttp<4.0.0,>=3.8.3->langchain_community) (2.4.0)\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in c:\\users\\user\\practices\\end-to-end-mcq\\myenv\\lib\\site-packages (from aiohttp<4.0.0,>=3.8.3->langchain_community) (1.3.1)\n",
      "Requirement already satisfied: attrs>=17.3.0 in c:\\users\\user\\practices\\end-to-end-mcq\\myenv\\lib\\site-packages (from aiohttp<4.0.0,>=3.8.3->langchain_community) (24.2.0)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in c:\\users\\user\\practices\\end-to-end-mcq\\myenv\\lib\\site-packages (from aiohttp<4.0.0,>=3.8.3->langchain_community) (1.4.1)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in c:\\users\\user\\practices\\end-to-end-mcq\\myenv\\lib\\site-packages (from aiohttp<4.0.0,>=3.8.3->langchain_community) (6.0.5)\n",
      "Requirement already satisfied: yarl<2.0,>=1.0 in c:\\users\\user\\practices\\end-to-end-mcq\\myenv\\lib\\site-packages (from aiohttp<4.0.0,>=3.8.3->langchain_community) (1.11.0)\n",
      "Collecting marshmallow<4.0.0,>=3.18.0 (from dataclasses-json<0.7,>=0.5.7->langchain_community)\n",
      "  Downloading marshmallow-3.22.0-py3-none-any.whl.metadata (7.2 kB)\n",
      "Collecting typing-inspect<1,>=0.4.0 (from dataclasses-json<0.7,>=0.5.7->langchain_community)\n",
      "  Downloading typing_inspect-0.9.0-py3-none-any.whl.metadata (1.5 kB)\n",
      "Requirement already satisfied: langchain-text-splitters<0.3.0,>=0.2.0 in c:\\users\\user\\practices\\end-to-end-mcq\\myenv\\lib\\site-packages (from langchain<0.3.0,>=0.2.16->langchain_community) (0.2.4)\n",
      "Requirement already satisfied: pydantic<3,>=1 in c:\\users\\user\\practices\\end-to-end-mcq\\myenv\\lib\\site-packages (from langchain<0.3.0,>=0.2.16->langchain_community) (2.9.1)\n",
      "Requirement already satisfied: jsonpatch<2.0,>=1.33 in c:\\users\\user\\practices\\end-to-end-mcq\\myenv\\lib\\site-packages (from langchain-core<0.3.0,>=0.2.38->langchain_community) (1.33)\n",
      "Requirement already satisfied: packaging<25,>=23.2 in c:\\users\\user\\practices\\end-to-end-mcq\\myenv\\lib\\site-packages (from langchain-core<0.3.0,>=0.2.38->langchain_community) (24.1)\n",
      "Requirement already satisfied: typing-extensions>=4.7 in c:\\users\\user\\practices\\end-to-end-mcq\\myenv\\lib\\site-packages (from langchain-core<0.3.0,>=0.2.38->langchain_community) (4.12.2)\n",
      "Requirement already satisfied: httpx<1,>=0.23.0 in c:\\users\\user\\practices\\end-to-end-mcq\\myenv\\lib\\site-packages (from langsmith<0.2.0,>=0.1.0->langchain_community) (0.27.2)\n",
      "Requirement already satisfied: orjson<4.0.0,>=3.9.14 in c:\\users\\user\\practices\\end-to-end-mcq\\myenv\\lib\\site-packages (from langsmith<0.2.0,>=0.1.0->langchain_community) (3.10.7)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\user\\practices\\end-to-end-mcq\\myenv\\lib\\site-packages (from requests<3,>=2->langchain_community) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\user\\practices\\end-to-end-mcq\\myenv\\lib\\site-packages (from requests<3,>=2->langchain_community) (3.8)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\user\\practices\\end-to-end-mcq\\myenv\\lib\\site-packages (from requests<3,>=2->langchain_community) (2.2.2)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\user\\practices\\end-to-end-mcq\\myenv\\lib\\site-packages (from requests<3,>=2->langchain_community) (2024.8.30)\n",
      "Requirement already satisfied: greenlet!=0.4.17 in c:\\users\\user\\practices\\end-to-end-mcq\\myenv\\lib\\site-packages (from SQLAlchemy<3,>=1.4->langchain_community) (3.0.3)\n",
      "Requirement already satisfied: anyio in c:\\users\\user\\practices\\end-to-end-mcq\\myenv\\lib\\site-packages (from httpx<1,>=0.23.0->langsmith<0.2.0,>=0.1.0->langchain_community) (4.4.0)\n",
      "Requirement already satisfied: httpcore==1.* in c:\\users\\user\\practices\\end-to-end-mcq\\myenv\\lib\\site-packages (from httpx<1,>=0.23.0->langsmith<0.2.0,>=0.1.0->langchain_community) (1.0.5)\n",
      "Requirement already satisfied: sniffio in c:\\users\\user\\practices\\end-to-end-mcq\\myenv\\lib\\site-packages (from httpx<1,>=0.23.0->langsmith<0.2.0,>=0.1.0->langchain_community) (1.3.1)\n",
      "Requirement already satisfied: h11<0.15,>=0.13 in c:\\users\\user\\practices\\end-to-end-mcq\\myenv\\lib\\site-packages (from httpcore==1.*->httpx<1,>=0.23.0->langsmith<0.2.0,>=0.1.0->langchain_community) (0.14.0)\n",
      "Requirement already satisfied: jsonpointer>=1.9 in c:\\users\\user\\practices\\end-to-end-mcq\\myenv\\lib\\site-packages (from jsonpatch<2.0,>=1.33->langchain-core<0.3.0,>=0.2.38->langchain_community) (3.0.0)\n",
      "Requirement already satisfied: annotated-types>=0.6.0 in c:\\users\\user\\practices\\end-to-end-mcq\\myenv\\lib\\site-packages (from pydantic<3,>=1->langchain<0.3.0,>=0.2.16->langchain_community) (0.7.0)\n",
      "Requirement already satisfied: pydantic-core==2.23.3 in c:\\users\\user\\practices\\end-to-end-mcq\\myenv\\lib\\site-packages (from pydantic<3,>=1->langchain<0.3.0,>=0.2.16->langchain_community) (2.23.3)\n",
      "Collecting mypy-extensions>=0.3.0 (from typing-inspect<1,>=0.4.0->dataclasses-json<0.7,>=0.5.7->langchain_community)\n",
      "  Downloading mypy_extensions-1.0.0-py3-none-any.whl.metadata (1.1 kB)\n",
      "Downloading langchain_community-0.2.16-py3-none-any.whl (2.3 MB)\n",
      "   ---------------------------------------- 0.0/2.3 MB ? eta -:--:--\n",
      "   ---------------------------------------- 0.0/2.3 MB ? eta -:--:--\n",
      "   ---------------------------------------- 0.0/2.3 MB ? eta -:--:--\n",
      "   ---------------------------------------- 0.0/2.3 MB ? eta -:--:--\n",
      "   ---- ----------------------------------- 0.3/2.3 MB ? eta -:--:--\n",
      "   ---- ----------------------------------- 0.3/2.3 MB ? eta -:--:--\n",
      "   ---- ----------------------------------- 0.3/2.3 MB ? eta -:--:--\n",
      "   -------- ------------------------------- 0.5/2.3 MB 419.4 kB/s eta 0:00:05\n",
      "   -------- ------------------------------- 0.5/2.3 MB 419.4 kB/s eta 0:00:05\n",
      "   -------- ------------------------------- 0.5/2.3 MB 419.4 kB/s eta 0:00:05\n",
      "   ------------- -------------------------- 0.8/2.3 MB 430.1 kB/s eta 0:00:04\n",
      "   ------------- -------------------------- 0.8/2.3 MB 430.1 kB/s eta 0:00:04\n",
      "   ----------------- ---------------------- 1.0/2.3 MB 457.5 kB/s eta 0:00:03\n",
      "   ----------------- ---------------------- 1.0/2.3 MB 457.5 kB/s eta 0:00:03\n",
      "   ----------------- ---------------------- 1.0/2.3 MB 457.5 kB/s eta 0:00:03\n",
      "   ---------------------- ----------------- 1.3/2.3 MB 469.2 kB/s eta 0:00:03\n",
      "   ---------------------- ----------------- 1.3/2.3 MB 469.2 kB/s eta 0:00:03\n",
      "   -------------------------- ------------- 1.6/2.3 MB 476.6 kB/s eta 0:00:02\n",
      "   -------------------------- ------------- 1.6/2.3 MB 476.6 kB/s eta 0:00:02\n",
      "   -------------------------- ------------- 1.6/2.3 MB 476.6 kB/s eta 0:00:02\n",
      "   ------------------------------- -------- 1.8/2.3 MB 461.8 kB/s eta 0:00:02\n",
      "   ------------------------------- -------- 1.8/2.3 MB 461.8 kB/s eta 0:00:02\n",
      "   ------------------------------- -------- 1.8/2.3 MB 461.8 kB/s eta 0:00:02\n",
      "   ------------------------------- -------- 1.8/2.3 MB 461.8 kB/s eta 0:00:02\n",
      "   ----------------------------------- ---- 2.1/2.3 MB 443.1 kB/s eta 0:00:01\n",
      "   ----------------------------------- ---- 2.1/2.3 MB 443.1 kB/s eta 0:00:01\n",
      "   ---------------------------------------- 2.3/2.3 MB 449.8 kB/s eta 0:00:00\n",
      "Downloading dataclasses_json-0.6.7-py3-none-any.whl (28 kB)\n",
      "Downloading marshmallow-3.22.0-py3-none-any.whl (49 kB)\n",
      "Downloading typing_inspect-0.9.0-py3-none-any.whl (8.8 kB)\n",
      "Downloading mypy_extensions-1.0.0-py3-none-any.whl (4.7 kB)\n",
      "Installing collected packages: mypy-extensions, marshmallow, typing-inspect, dataclasses-json, langchain_community\n",
      "Successfully installed dataclasses-json-0.6.7 langchain_community-0.2.16 marshmallow-3.22.0 mypy-extensions-1.0.0 typing-inspect-0.9.0\n"
     ]
    }
   ],
   "source": [
    "!pip install langchain_community"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.chat_models import ChatOpenAI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting dotenv\n",
      "  Using cached dotenv-0.0.5.tar.gz (2.4 kB)\n",
      "  Preparing metadata (setup.py): started\n",
      "  Preparing metadata (setup.py): finished with status 'error'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  error: subprocess-exited-with-error\n",
      "  \n",
      "  × python setup.py egg_info did not run successfully.\n",
      "  │ exit code: 1\n",
      "  ╰─> [67 lines of output]\n",
      "      C:\\Users\\USER\\practices\\end-to-end-mcq\\myenv\\Lib\\site-packages\\setuptools\\__init__.py:94: _DeprecatedInstaller: setuptools.installer and fetch_build_eggs are deprecated.\n",
      "      !!\n",
      "      \n",
      "              ********************************************************************************\n",
      "              Requirements should be satisfied by a PEP 517 installer.\n",
      "              If you are using pip, you can try `pip install --use-pep517`.\n",
      "              ********************************************************************************\n",
      "      \n",
      "      !!\n",
      "        dist.fetch_build_eggs(dist.setup_requires)\n",
      "        error: subprocess-exited-with-error\n",
      "      \n",
      "        Ã— python setup.py egg_info did not run successfully.\n",
      "        â”‚ exit code: 1\n",
      "        â•°â”€> [1 lines of output]\n",
      "            ERROR: Can not execute `setup.py` since setuptools is not available in the build environment.\n",
      "            [end of output]\n",
      "      \n",
      "        note: This error originates from a subprocess, and is likely not a problem with pip.\n",
      "      error: metadata-generation-failed\n",
      "      \n",
      "      Ã— Encountered error while generating package metadata.\n",
      "      â•°â”€> See above for output.\n",
      "      \n",
      "      note: This is an issue with the package mentioned above, not pip.\n",
      "      hint: See above for details.\n",
      "      Traceback (most recent call last):\n",
      "        File \"C:\\Users\\USER\\practices\\end-to-end-mcq\\myenv\\Lib\\site-packages\\setuptools\\installer.py\", line 102, in _fetch_build_egg_no_warn\n",
      "          subprocess.check_call(cmd)\n",
      "        File \"C:\\Users\\USER\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\subprocess.py\", line 413, in check_call\n",
      "          raise CalledProcessError(retcode, cmd)\n",
      "      subprocess.CalledProcessError: Command '['C:\\\\Users\\\\USER\\\\practices\\\\end-to-end-mcq\\\\myenv\\\\Scripts\\\\python.exe', '-m', 'pip', '--disable-pip-version-check', 'wheel', '--no-deps', '-w', 'C:\\\\Users\\\\USER\\\\AppData\\\\Local\\\\Temp\\\\tmpmf3ctodm', '--quiet', 'distribute']' returned non-zero exit status 1.\n",
      "      \n",
      "      The above exception was the direct cause of the following exception:\n",
      "      \n",
      "      Traceback (most recent call last):\n",
      "        File \"<string>\", line 2, in <module>\n",
      "        File \"<pip-setuptools-caller>\", line 34, in <module>\n",
      "        File \"C:\\Users\\USER\\AppData\\Local\\Temp\\pip-install-zol2j5rx\\dotenv_bbdc32ce811547a1aea914ec40f0262d\\setup.py\", line 13, in <module>\n",
      "          setup(name='dotenv',\n",
      "        File \"C:\\Users\\USER\\practices\\end-to-end-mcq\\myenv\\Lib\\site-packages\\setuptools\\__init__.py\", line 116, in setup\n",
      "          _install_setup_requires(attrs)\n",
      "        File \"C:\\Users\\USER\\practices\\end-to-end-mcq\\myenv\\Lib\\site-packages\\setuptools\\__init__.py\", line 89, in _install_setup_requires\n",
      "          _fetch_build_eggs(dist)\n",
      "        File \"C:\\Users\\USER\\practices\\end-to-end-mcq\\myenv\\Lib\\site-packages\\setuptools\\__init__.py\", line 94, in _fetch_build_eggs\n",
      "          dist.fetch_build_eggs(dist.setup_requires)\n",
      "        File \"C:\\Users\\USER\\practices\\end-to-end-mcq\\myenv\\Lib\\site-packages\\setuptools\\dist.py\", line 617, in fetch_build_eggs\n",
      "          return _fetch_build_eggs(self, requires)\n",
      "                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "        File \"C:\\Users\\USER\\practices\\end-to-end-mcq\\myenv\\Lib\\site-packages\\setuptools\\installer.py\", line 39, in _fetch_build_eggs\n",
      "          resolved_dists = pkg_resources.working_set.resolve(\n",
      "                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "        File \"C:\\Users\\USER\\practices\\end-to-end-mcq\\myenv\\Lib\\site-packages\\pkg_resources\\__init__.py\", line 897, in resolve\n",
      "          dist = self._resolve_dist(\n",
      "                 ^^^^^^^^^^^^^^^^^^^\n",
      "        File \"C:\\Users\\USER\\practices\\end-to-end-mcq\\myenv\\Lib\\site-packages\\pkg_resources\\__init__.py\", line 933, in _resolve_dist\n",
      "          dist = best[req.key] = env.best_match(\n",
      "                                 ^^^^^^^^^^^^^^^\n",
      "        File \"C:\\Users\\USER\\practices\\end-to-end-mcq\\myenv\\Lib\\site-packages\\pkg_resources\\__init__.py\", line 1271, in best_match\n",
      "          return self.obtain(req, installer)\n",
      "                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "        File \"C:\\Users\\USER\\practices\\end-to-end-mcq\\myenv\\Lib\\site-packages\\pkg_resources\\__init__.py\", line 1307, in obtain\n",
      "          return installer(requirement) if installer else None\n",
      "                 ^^^^^^^^^^^^^^^^^^^^^^\n",
      "        File \"C:\\Users\\USER\\practices\\end-to-end-mcq\\myenv\\Lib\\site-packages\\setuptools\\installer.py\", line 104, in _fetch_build_egg_no_warn\n",
      "          raise DistutilsError(str(e)) from e\n",
      "      distutils.errors.DistutilsError: Command '['C:\\\\Users\\\\USER\\\\practices\\\\end-to-end-mcq\\\\myenv\\\\Scripts\\\\python.exe', '-m', 'pip', '--disable-pip-version-check', 'wheel', '--no-deps', '-w', 'C:\\\\Users\\\\USER\\\\AppData\\\\Local\\\\Temp\\\\tmpmf3ctodm', '--quiet', 'distribute']' returned non-zero exit status 1.\n",
      "      [end of output]\n",
      "  \n",
      "  note: This error originates from a subprocess, and is likely not a problem with pip.\n",
      "error: metadata-generation-failed\n",
      "\n",
      "× Encountered error while generating package metadata.\n",
      "╰─> See above for output.\n",
      "\n",
      "note: This is an issue with the package mentioned above, not pip.\n",
      "hint: See above for details.\n"
     ]
    }
   ],
   "source": [
    "!pip install dotenv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from dotenv import load_dotenv\n",
    "\n",
    "load_dotenv()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "KEY=os.getenv(\"OPENAI_API_KEY\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_openai import ChatOpenAI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "llm = ChatOpenAI(openai_api_key=KEY, model_name=\"gpt-4o-mini\", temperature=0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.llms import OpenAI\n",
    "from langchain.prompts import PromptTemplate\n",
    "from langchain.chains import LLMChain\n",
    "from langchain.callbacks import get_openai_callback\n",
    "from langchain.chains import SequentialChain\n",
    "import PyPDF2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ChatOpenAI(client=<openai.resources.chat.completions.Completions object at 0x0000025F1B522330>, async_client=<openai.resources.chat.completions.AsyncCompletions object at 0x0000025F1B5238F0>, root_client=<openai.OpenAI object at 0x0000025F1B521160>, root_async_client=<openai.AsyncOpenAI object at 0x0000025F1B522360>, model_name='gpt-4o-mini', temperature=0.5, openai_api_key=SecretStr('**********'), openai_proxy='')"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "llm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "RESPONSE_JSON = {\n",
    "    \"1\": {\n",
    "        \"mcq\": \"multiple choice question\",\n",
    "        \"options\": {\n",
    "            \"a\": \"choice here\",\n",
    "            \"b\": \"choice here\",\n",
    "            \"c\": \"choice here\",\n",
    "            \"d\": \"choice here\",\n",
    "        },\n",
    "        \"correct\": \"correct answer\",\n",
    "    },\n",
    "    \"2\": {\n",
    "        \"mcq\": \"multiple choice question\",\n",
    "        \"options\": {\n",
    "            \"a\": \"choice here\",\n",
    "            \"b\": \"choice here\",\n",
    "            \"c\": \"choice here\",\n",
    "            \"d\": \"choice here\",\n",
    "        },\n",
    "        \"correct\": \"correct answer\",\n",
    "    },\n",
    "    \"3\": {\n",
    "        \"mcq\": \"multiple choice question\",\n",
    "        \"options\": {\n",
    "            \"a\": \"choice here\",\n",
    "            \"b\": \"choice here\",\n",
    "            \"c\": \"choice here\",\n",
    "            \"d\": \"choice here\",\n",
    "        },\n",
    "        \"correct\": \"correct answer\",\n",
    "    },\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "TEMPLATE=\"\"\"\n",
    "Text:{text}\n",
    "You are an expert MCQ maker. Given the above text, it is your job to \\\n",
    "create a quiz  of {number} multiple choice questions for {subject} students in {tone} tone. \n",
    "Make sure the questions are not repeated and check all the questions to be conforming the text as well.\n",
    "Make sure to format your response like  RESPONSE_JSON below  and use it as a guide. \\\n",
    "Ensure to make {number} MCQs\n",
    "### RESPONSE_JSON\n",
    "{response_json}\n",
    "\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "quiz_generation_prompt = PromptTemplate(\n",
    "    input_variables=[\"text\", \"number\", \"subject\", \"tone\", \"response_json\"],\n",
    "    template=TEMPLATE\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "quizz_chain = LLMChain(llm=llm, prompt=quiz_generation_prompt, output_key='quiz', verbose=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "TEMPLATE2=\"\"\"\n",
    "You are an expert english grammarian and writer. Given a Multiple Choice Quiz for {subject} students.\\\n",
    "You need to evaluate the complexity of the question and give a complete analysis of the quiz. Only use at max 50 words for complexity analysis. \n",
    "if the quiz is not at per with the cognitive and analytical abilities of the students,\\\n",
    "update the quiz questions which needs to be changed and change the tone such that it perfectly fits the student abilities\n",
    "Quiz_MCQs:\n",
    "{quiz}\n",
    "\n",
    "Check from an expert English Writer of the above quiz:\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "quizz_evaluation_prompt = PromptTemplate(\n",
    "    input_variables=[\"subject\", \"quiz\"],\n",
    "    template=TEMPLATE2\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "review_chain = LLMChain(llm=llm, prompt=quizz_evaluation_prompt, output_key='review', verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "generate_evaluate_chain=SequentialChain(chains=[quizz_chain, review_chain], input_variables=[\"text\", \"number\", \"subject\", \"tone\", \"response_json\"],\n",
    "                                        output_variables=[\"quiz\", \"review\"], verbose=True,)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "file_path = \"C:\\\\Users\\\\USER\\\\practices\\\\end-to-end-mcq\\\\data.txt\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(file_path, \"r\") as file:\n",
    "    text = file.read()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Biology is the scientific study of life.[1][2][3] It is a natural science with a broad scope but has several unifying themes that tie it together as a single, coherent field.[1][2][3] For instance, all organisms are made up of cells that process hereditary information encoded in genes, which can be transmitted to future generations. Another major theme is evolution, which explains the unity and diversity of life.[1][2][3] Energy processing is also important to life as it allows organisms to move, grow, and reproduce.[1][2][3] Finally, all organisms are able to regulate their own internal environments.[1][2][3][4][5]\n",
      "\n",
      "Biologists are able to study life at multiple levels of organization,[1] from the molecular biology of a cell to the anatomy and physiology of plants and animals, and evolution of populations.[1][6] Hence, there are multiple subdisciplines within biology, each defined by the nature of their research questions and the tools that they use.[7][8][9] Like other scientists, biologists use the scientific method to make observations, pose questions, generate hypotheses, perform experiments, and form conclusions about the world around them.[1]\n",
      "\n",
      "Life on Earth, which emerged more than 3.7 billion years ago,[10] is immensely diverse. Biologists have sought to study and classify the various forms of life, from prokaryotic organisms such as archaea and bacteria to eukaryotic organisms such as protists, fungi, plants, and animals. These various organisms contribute to the biodiversity of an ecosystem, where they play specialized roles in the cycling of nutrients and energy through their biophysical environment.\n"
     ]
    }
   ],
   "source": [
    "print(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'{\"1\": {\"mcq\": \"multiple choice question\", \"options\": {\"a\": \"choice here\", \"b\": \"choice here\", \"c\": \"choice here\", \"d\": \"choice here\"}, \"correct\": \"correct answer\"}, \"2\": {\"mcq\": \"multiple choice question\", \"options\": {\"a\": \"choice here\", \"b\": \"choice here\", \"c\": \"choice here\", \"d\": \"choice here\"}, \"correct\": \"correct answer\"}, \"3\": {\"mcq\": \"multiple choice question\", \"options\": {\"a\": \"choice here\", \"b\": \"choice here\", \"c\": \"choice here\", \"d\": \"choice here\"}, \"correct\": \"correct answer\"}}'"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "json.dumps(RESPONSE_JSON)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new SequentialChain chain...\u001b[0m\n",
      "\n",
      "\n",
      "\u001b[1m> Entering new LLMChain chain...\u001b[0m\n",
      "Prompt after formatting:\n",
      "\u001b[32;1m\u001b[1;3m\n",
      "Text:Biology is the scientific study of life.[1][2][3] It is a natural science with a broad scope but has several unifying themes that tie it together as a single, coherent field.[1][2][3] For instance, all organisms are made up of cells that process hereditary information encoded in genes, which can be transmitted to future generations. Another major theme is evolution, which explains the unity and diversity of life.[1][2][3] Energy processing is also important to life as it allows organisms to move, grow, and reproduce.[1][2][3] Finally, all organisms are able to regulate their own internal environments.[1][2][3][4][5]\n",
      "\n",
      "Biologists are able to study life at multiple levels of organization,[1] from the molecular biology of a cell to the anatomy and physiology of plants and animals, and evolution of populations.[1][6] Hence, there are multiple subdisciplines within biology, each defined by the nature of their research questions and the tools that they use.[7][8][9] Like other scientists, biologists use the scientific method to make observations, pose questions, generate hypotheses, perform experiments, and form conclusions about the world around them.[1]\n",
      "\n",
      "Life on Earth, which emerged more than 3.7 billion years ago,[10] is immensely diverse. Biologists have sought to study and classify the various forms of life, from prokaryotic organisms such as archaea and bacteria to eukaryotic organisms such as protists, fungi, plants, and animals. These various organisms contribute to the biodiversity of an ecosystem, where they play specialized roles in the cycling of nutrients and energy through their biophysical environment.\n",
      "You are an expert MCQ maker. Given the above text, it is your job to create a quiz  of 3 multiple choice questions for Biology students in formal tone. \n",
      "Make sure the questions are not repeated and check all the questions to be conforming the text as well.\n",
      "Make sure to format your response like  RESPONSE_JSON below  and use it as a guide. Ensure to make 3 MCQs\n",
      "### RESPONSE_JSON\n",
      "{\"1\": {\"mcq\": \"multiple choice question\", \"options\": {\"a\": \"choice here\", \"b\": \"choice here\", \"c\": \"choice here\", \"d\": \"choice here\"}, \"correct\": \"correct answer\"}, \"2\": {\"mcq\": \"multiple choice question\", \"options\": {\"a\": \"choice here\", \"b\": \"choice here\", \"c\": \"choice here\", \"d\": \"choice here\"}, \"correct\": \"correct answer\"}, \"3\": {\"mcq\": \"multiple choice question\", \"options\": {\"a\": \"choice here\", \"b\": \"choice here\", \"c\": \"choice here\", \"d\": \"choice here\"}, \"correct\": \"correct answer\"}}\n",
      "\n",
      "\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n",
      "\n",
      "\n",
      "\u001b[1m> Entering new LLMChain chain...\u001b[0m\n",
      "Prompt after formatting:\n",
      "\u001b[32;1m\u001b[1;3m\n",
      "You are an expert english grammarian and writer. Given a Multiple Choice Quiz for Biology students.You need to evaluate the complexity of the question and give a complete analysis of the quiz. Only use at max 50 words for complexity analysis. \n",
      "if the quiz is not at per with the cognitive and analytical abilities of the students,update the quiz questions which needs to be changed and change the tone such that it perfectly fits the student abilities\n",
      "Quiz_MCQs:\n",
      "{\n",
      "  \"1\": {\n",
      "    \"mcq\": \"What is the primary focus of biology as a scientific discipline?\",\n",
      "    \"options\": {\n",
      "      \"a\": \"The study of chemical reactions\",\n",
      "      \"b\": \"The scientific study of life\",\n",
      "      \"c\": \"The exploration of the universe\",\n",
      "      \"d\": \"The analysis of physical forces\"\n",
      "    },\n",
      "    \"correct\": \"b\"\n",
      "  },\n",
      "  \"2\": {\n",
      "    \"mcq\": \"Which of the following is NOT mentioned as a major theme in biology?\",\n",
      "    \"options\": {\n",
      "      \"a\": \"Energy processing\",\n",
      "      \"b\": \"Evolution\",\n",
      "      \"c\": \"Genetic engineering\",\n",
      "      \"d\": \"Cellular organization\"\n",
      "    },\n",
      "    \"correct\": \"c\"\n",
      "  },\n",
      "  \"3\": {\n",
      "    \"mcq\": \"How do biologists approach their research according to the text?\",\n",
      "    \"options\": {\n",
      "      \"a\": \"By relying solely on theoretical models\",\n",
      "      \"b\": \"By using the scientific method\",\n",
      "      \"c\": \"By conducting surveys and polls\",\n",
      "      \"d\": \"By performing only observational studies\"\n",
      "    },\n",
      "    \"correct\": \"b\"\n",
      "  }\n",
      "}\n",
      "\n",
      "Check from an expert English Writer of the above quiz:\n",
      "\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "with get_openai_callback() as cb:\n",
    "    response = generate_evaluate_chain.invoke({\n",
    "        \"text\": text,\n",
    "        \"number\": 3,\n",
    "        \"subject\": \"Biology\",\n",
    "        \"tone\": \"formal\",\n",
    "        \"response_json\": json.dumps(RESPONSE_JSON)\n",
    "    })\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total Tokens:1661\n",
      "Prompt Tokens:948\n",
      "Completion Tokens:713\n",
      "Total Cost:0.00057\n"
     ]
    }
   ],
   "source": [
    "print(f\"Total Tokens:{cb.total_tokens}\")\n",
    "print(f\"Prompt Tokens:{cb.prompt_tokens}\")\n",
    "print(f\"Completion Tokens:{cb.completion_tokens}\")\n",
    "print(f\"Total Cost:{cb.total_cost}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'text': 'Biology is the scientific study of life.[1][2][3] It is a natural science with a broad scope but has several unifying themes that tie it together as a single, coherent field.[1][2][3] For instance, all organisms are made up of cells that process hereditary information encoded in genes, which can be transmitted to future generations. Another major theme is evolution, which explains the unity and diversity of life.[1][2][3] Energy processing is also important to life as it allows organisms to move, grow, and reproduce.[1][2][3] Finally, all organisms are able to regulate their own internal environments.[1][2][3][4][5]\\n\\nBiologists are able to study life at multiple levels of organization,[1] from the molecular biology of a cell to the anatomy and physiology of plants and animals, and evolution of populations.[1][6] Hence, there are multiple subdisciplines within biology, each defined by the nature of their research questions and the tools that they use.[7][8][9] Like other scientists, biologists use the scientific method to make observations, pose questions, generate hypotheses, perform experiments, and form conclusions about the world around them.[1]\\n\\nLife on Earth, which emerged more than 3.7 billion years ago,[10] is immensely diverse. Biologists have sought to study and classify the various forms of life, from prokaryotic organisms such as archaea and bacteria to eukaryotic organisms such as protists, fungi, plants, and animals. These various organisms contribute to the biodiversity of an ecosystem, where they play specialized roles in the cycling of nutrients and energy through their biophysical environment.',\n",
       " 'number': 3,\n",
       " 'subject': 'Biology',\n",
       " 'tone': 'formal',\n",
       " 'response_json': '{\"1\": {\"mcq\": \"multiple choice question\", \"options\": {\"a\": \"choice here\", \"b\": \"choice here\", \"c\": \"choice here\", \"d\": \"choice here\"}, \"correct\": \"correct answer\"}, \"2\": {\"mcq\": \"multiple choice question\", \"options\": {\"a\": \"choice here\", \"b\": \"choice here\", \"c\": \"choice here\", \"d\": \"choice here\"}, \"correct\": \"correct answer\"}, \"3\": {\"mcq\": \"multiple choice question\", \"options\": {\"a\": \"choice here\", \"b\": \"choice here\", \"c\": \"choice here\", \"d\": \"choice here\"}, \"correct\": \"correct answer\"}}',\n",
       " 'quiz': '{\\n  \"1\": {\\n    \"mcq\": \"What is the primary focus of biology as a scientific discipline?\",\\n    \"options\": {\\n      \"a\": \"The study of chemical reactions\",\\n      \"b\": \"The scientific study of life\",\\n      \"c\": \"The exploration of the universe\",\\n      \"d\": \"The analysis of physical forces\"\\n    },\\n    \"correct\": \"b\"\\n  },\\n  \"2\": {\\n    \"mcq\": \"Which of the following is NOT mentioned as a major theme in biology?\",\\n    \"options\": {\\n      \"a\": \"Energy processing\",\\n      \"b\": \"Evolution\",\\n      \"c\": \"Genetic engineering\",\\n      \"d\": \"Cellular organization\"\\n    },\\n    \"correct\": \"c\"\\n  },\\n  \"3\": {\\n    \"mcq\": \"How do biologists approach their research according to the text?\",\\n    \"options\": {\\n      \"a\": \"By relying solely on theoretical models\",\\n      \"b\": \"By using the scientific method\",\\n      \"c\": \"By conducting surveys and polls\",\\n      \"d\": \"By performing only observational studies\"\\n    },\\n    \"correct\": \"b\"\\n  }\\n}',\n",
       " 'review': '**Complexity Analysis:**  \\nThe questions are straightforward, testing basic knowledge of biology. They require recall rather than higher-order thinking, making them suitable for introductory students but potentially too simplistic for advanced learners.\\n\\n**Quiz Updates:**\\n\\n1. **Question 1:**  \\n   **Original:** What is the primary focus of biology as a scientific discipline?  \\n   **Revised:** What key aspect of life does biology primarily investigate?  \\n   **Rationale:** The wording is simplified for clarity while maintaining focus.\\n\\n2. **Question 2:**  \\n   **Original:** Which of the following is NOT mentioned as a major theme in biology?  \\n   **Revised:** Which of these concepts is least associated with the major themes of biology?  \\n   **Rationale:** The revision clarifies the question\\'s intent.\\n\\n3. **Question 3:**  \\n   **Original:** How do biologists approach their research according to the text?  \\n   **Revised:** What method do biologists typically use to conduct their research?  \\n   **Rationale:** The revision simplifies the question while keeping the focus on methodology.\\n\\n**Updated Quiz_MCQs:**\\n\\n{\\n  \"1\": {\\n    \"mcq\": \"What key aspect of life does biology primarily investigate?\",\\n    \"options\": {\\n      \"a\": \"The study of chemical reactions\",\\n      \"b\": \"The scientific study of life\",\\n      \"c\": \"The exploration of the universe\",\\n      \"d\": \"The analysis of physical forces\"\\n    },\\n    \"correct\": \"b\"\\n  },\\n  \"2\": {\\n    \"mcq\": \"Which of these concepts is least associated with the major themes of biology?\",\\n    \"options\": {\\n      \"a\": \"Energy processing\",\\n      \"b\": \"Evolution\",\\n      \"c\": \"Genetic engineering\",\\n      \"d\": \"Cellular organization\"\\n    },\\n    \"correct\": \"c\"\\n  },\\n  \"3\": {\\n    \"mcq\": \"What method do biologists typically use to conduct their research?\",\\n    \"options\": {\\n      \"a\": \"By relying solely on theoretical models\",\\n      \"b\": \"By using the scientific method\",\\n      \"c\": \"By conducting surveys and polls\",\\n      \"d\": \"By performing only observational studies\"\\n    },\\n    \"correct\": \"b\"\\n  }\\n}'}"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "quiz = json.loads(response['quiz'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "quiz_table_data =[]\n",
    "for key, value in json.loads(response['quiz']).items():\n",
    "    quiz_table_data.append([key, value['mcq'], value['correct'], value['options']['a'], value['options']['b'], value['options']['c'], value['options']['d']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Question No</th>\n",
       "      <th>MCQ</th>\n",
       "      <th>Option A</th>\n",
       "      <th>Option B</th>\n",
       "      <th>Option C</th>\n",
       "      <th>Option D</th>\n",
       "      <th>Correct Answer</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>What is the primary focus of biology as a scie...</td>\n",
       "      <td>b</td>\n",
       "      <td>The study of chemical reactions</td>\n",
       "      <td>The scientific study of life</td>\n",
       "      <td>The exploration of the universe</td>\n",
       "      <td>The analysis of physical forces</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>Which of the following is NOT mentioned as a m...</td>\n",
       "      <td>c</td>\n",
       "      <td>Energy processing</td>\n",
       "      <td>Evolution</td>\n",
       "      <td>Genetic engineering</td>\n",
       "      <td>Cellular organization</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>How do biologists approach their research acco...</td>\n",
       "      <td>b</td>\n",
       "      <td>By relying solely on theoretical models</td>\n",
       "      <td>By using the scientific method</td>\n",
       "      <td>By conducting surveys and polls</td>\n",
       "      <td>By performing only observational studies</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Question No                                                MCQ Option A  \\\n",
       "0           1  What is the primary focus of biology as a scie...        b   \n",
       "1           2  Which of the following is NOT mentioned as a m...        c   \n",
       "2           3  How do biologists approach their research acco...        b   \n",
       "\n",
       "                                  Option B                        Option C  \\\n",
       "0          The study of chemical reactions    The scientific study of life   \n",
       "1                        Energy processing                       Evolution   \n",
       "2  By relying solely on theoretical models  By using the scientific method   \n",
       "\n",
       "                          Option D                            Correct Answer  \n",
       "0  The exploration of the universe           The analysis of physical forces  \n",
       "1              Genetic engineering                     Cellular organization  \n",
       "2  By conducting surveys and polls  By performing only observational studies  "
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame(quiz_table_data, columns=[\"Question No\", \"MCQ\", \"Option A\", \"Option B\", \"Option C\", \"Option D\",  \"Correct Answer\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "myenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
